{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "HSHwOTEgUbQd",
    "outputId": "6419965b-9c60-4a31-b18e-d39d2eb9184e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/c0/b9714b4fb164368843b41482a3cac11938021871adf99bf5aaa3980b0182/praw-6.5.1-py3-none-any.whl (134kB)\n",
      "\r",
      "\u001b[K     |██▍                             | 10kB 18.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 20kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 30kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 40kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 51kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 61kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 71kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 81kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 92kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 102kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 112kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 122kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 133kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 143kB 2.8MB/s \n",
      "\u001b[?25hCollecting update-checker>=0.16\n",
      "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
      "Collecting websocket-client>=0.54.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 48.8MB/s \n",
      "\u001b[?25hCollecting prawcore<2.0,>=1.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/76/b5/ce6282dea45cba6f08a30e25d18e0f3d33277e2c9fcbda75644b8dc0089b/prawcore-1.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->praw) (2.21.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.54.0->praw) (1.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->praw) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->praw) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->praw) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->praw) (1.24.3)\n",
      "Installing collected packages: update-checker, websocket-client, prawcore, praw\n",
      "Successfully installed praw-6.5.1 prawcore-1.0.1 update-checker-0.16 websocket-client-0.57.0\n"
     ]
    }
   ],
   "source": [
    "#Upload the mastodon_topics.csv file which Mo sent\n",
    "import pandas as pd\n",
    "!pip install praw\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-h0vVhmpUxqw"
   },
   "outputs": [],
   "source": [
    "# #Tester code\n",
    "# #If this works extract all possible subreddit's data\n",
    "\n",
    "# posts = []\n",
    "# ml_subreddit = reddit.subreddit('technology').hot(limit=1000)\n",
    "# for post in ml_subreddit:\n",
    "#     posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
    "# posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
    "# print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "yXZxdn4tVjzm",
    "outputId": "527793e5-4469-4819-c6cd-25bc94ea2c8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fandom\n",
      "lgbtq+\n"
     ]
    }
   ],
   "source": [
    "filtering = pd.read_csv('mastodon_counts.csv')\n",
    "new_filt = filtering.sort_values(by='userCount', ascending=False)\n",
    "subreddit_all = list(new_filt['topic'])[0:35]\n",
    "# print(subreddit_all)\n",
    "#importing our error which we get if the subreddit doesnt exist\n",
    "from prawcore.exceptions import Forbidden\n",
    "\n",
    "#trying to comment (we may be banned)\n",
    "for i in subreddit_all:\n",
    "  try:\n",
    "      print(i)\n",
    "      posts = []\n",
    "      ml_subreddit = reddit.subreddit(i).hot(limit=10000)\n",
    "      for post in ml_subreddit:\n",
    "          posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
    "      posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
    "      posts.to_csv('reddit_data_without_users.csv' , mode='a')\n",
    "  except Forbidden or NotFound: #might have to manually do it sometimes\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "id": "U1fMvofWgQhn",
    "outputId": "23413ec7-d5de-461c-b365-6bca232bd9a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research\n",
      "fetish\n",
      "data\n",
      "Teachers\n",
      "academia\n",
      "visualization\n",
      "tumblr\n",
      "geek\n",
      "LGBTQ\n",
      "subreddit\n",
      "ABDL\n",
      "bdsm\n",
      "aikatsu\n",
      "Sculpture\n",
      "fandom\n",
      "STEM\n",
      "Jokes\n",
      "dev\n",
      "Design\n",
      "Mastodon\n",
      "work\n",
      "Students\n",
      "nsfw\n"
     ]
    }
   ],
   "source": [
    "subreddit_all = list(set(list(pd.read_csv('reddit_data_without_users.csv')['subreddit'])))\n",
    "# print(subreddit_all)\n",
    "user_data = []\n",
    "\n",
    "for i in subreddit_all:\n",
    "  print(i)\n",
    "  subreddit = reddit.subreddit(i)\n",
    "  user_data.append([i,subreddit.subscribers,subreddit.accounts_active,subreddit.accounts_active_is_fuzzed,subreddit.active_user_count])\n",
    "user_data = pd.DataFrame(user_data, columns=['Subreddit name','Number of subscribers','Active accounts','Active Fuzzed accounts','Active user count'])\n",
    "user_data.to_csv('reddit_data_with_user.csv', mode = 'w')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ECE143_reddit_datascraping.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
